# Base Atari DQN configuration skeleton
seed: 42

env:
  id: "ALE/Pong-v5"
  frame_stack: 4
  render_mode: null  # set to "human" or "rgb_array" when needed

training:
  total_steps: 1000000
  start_steps: 50000
  batch_size: 32
  gamma: 0.99
  lr: 0.00025
  target_update_freq: 10000
  eval_interval: 100000
  max_grad_norm: 10.0

replay_buffer:
  capacity: 1000000
  min_replay_size: 50000
  prioritized: false

exploration:
  epsilon_start: 1.0
  epsilon_end: 0.1
  epsilon_decay_frames: 1000000

logging:
  log_dir: "logs/atari_dqn"
  checkpoint_interval: 100000
  video_interval: null

# Note: This file is a placeholder. Connect it to the train/eval code once implemented.
